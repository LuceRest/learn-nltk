Pt 1 :

- Tokenizing → Tahap pemotongan string atau kalimat input berdasarkan tiap kata yang menyusunnya.

- word_tokenize() ~> Berfungsi untuk memisah suatu kalimat menjadi kata-kata (dipisahkan berdasarkan spasi).
- word_tokenize(<kalimat yg ingin dipisah>)

- sent_tokenize() ~> Berfungsi untuk memisahkan paragraf menjadi kalimat-kalimat (dipisahkan berdasarkan titik dan tanda baca).
- sent_tokenize(<paragraf yg ingin dipisah>)



Pt 2 :

- Stop Words disebut juga Filtering
- Filtering → Tahap pemilihan kata-kata penting dari hasil token, yaitu katakata apa saja yang akan digunakan untuk mewakili dokumen

- stopwords.words() ~> Berfungsi untuk mengambil data stopwords dengan bahasa tertentu.
- stopwords.words(<bahasa stopword>)



Pt 3 :

- Stemming → Tahap mencari kata dasar (root) dari setiap kata hasil filtering.

- PorterStemmer().stem() ~> Berfungsi untuk melakukan stemming pada suatu kata.
- PorterStemmer().stem(<word>)



Pt  4 :

- Tagging
    Tahap untuk mencari bentuk awal dari tiap kata lampau atau hasil dari stemming yang masih memuat beberapa kata lampau yang dikembalikan ke bentuk awalnya.
    
- Punkt Sentence Tokenizer
    Tokenizer ini membagi teks menjadi daftar kalimat, dengan menggunakan algoritma yang tidak diawasi untuk membangun model kata singkatan, kolokasi, dan kata yang memulai kalimat. Itu harus dilatih pada banyak koleksi plaintext dalam bahasa target sebelum dapat digunakan.

- PoS tagging → Proses memberikan label kelas kata secara otomatis pada setiap kata yang ada pada suatu teks atau dokumen.

- List of Universal POS tags:
    • ADJ : Adjective
    • ADV : Adposition
    • ADP : Adverb
    • AUX : Auxiliary
    • CCONJ : Coordinating Conjuction
    • DET : Determiner
    • INTJ : Interjection
    • NOUN : Noun
    • NUM : Numeral
    • PART : Particle
    • PRON : Pronoun
    • PROPN : Proper Noun
    • PUNCT : Punctuation
    • SCONJ : Subordinating Conjuction
    • SYM : Symbol
    • VERB : Verb
    • X : Other

- Another LIST OF TAGS : 
    • CC : coordinating conjunction
    • CD : cardinal digit
    • DT : determiner
    • EX : existential there (like: “there is” … think of it like “there exists”)
    • FW : foreign word
    • IN : preposition/subordinating conjunction
    • JJ : adjective ‘big’
    • JJR : adjective, comparative ‘bigger’
    • JJS : adjective, superlative ‘biggest’
    • LS : list marker 1)
    • MD : modal could, will
    • NN : noun, singular ‘desk’
    • NNS : noun plural ‘desks’
    • NNP : proper noun, singular ‘Harrison’
    • NNPS : proper noun, plural ‘Americans’
    • PDT : predeterminer ‘all the kids’
    • POS : possessive ending parent‘s
    • PRP : personal pronoun I, he, she
    • PRPS : possessive pronoun my, his, hers
    • RB : adverb very, silently,
    • RBR : adverb, comparative better
    • RBS : adverb, superlative best
    • RP : particle give up
    • TO : to go ‘to‘ the store.
    • UH : interjection errrrrrrrm
    • VB : verb, base form take
    • VBD : verb, past tense took
    • VBG : verb, gerund/present participle taking
    • VBN : verb, past participle taken
    • VBP : verb, sing. present, non-3d take
    • VBZ : verb, 3rd person sing. present takes
    • WDT : wh-determiner which
    • WP : wh-pronoun who, what
    • WPS : possessive wh-pronoun whose
    • WRB : wh-abverb where, when



Pt 5 :

- Proses chunking dilakukan untuk mendapatkan informasi mengenai struktur kalimat.
- Chunking              → Proses yang mana ketika informassi memasuki memori, ia dapat dikodekan ulang sehingga konsep-konsep yang terkait dapat dikelompokkan bersama menjadi satu potongan.
- Chunking ini sering digunakan sebagai teknik menghafal.

- chunk.RegexpParser    → Menggunakan satu set pola ekspresi reguler untuk menentukan perilaku parser.



Pt 7 :

- nltk.chunk.ne_chunk() ~> Berfungsi untuk memberi nama pada entity chunker untuk memotong (chunk) daftar token yang diberi tag.
- nltk.chunk.ne_chunk(<tagged tokens*>,* binary=False/True)
    - binary = False    ~> Berfungsi untuk menampilkan nama entity chunker.
    - binary = True     ~> Berfungsi untuk tidak menampilkan nama entity chunker.



Pt 8 :

- Lemmatization → Proses yang bertujuan untuk melakukan normalisasi pada teks/kata dengan berdasarkan pada bentuk dasar yang merupakan bentuk lemma-nya.
- Lemma         → Bentuk dasar dari sebuah kata yang memiliki arti tertentu berdasar pada kamus.

- WordNetLemmatizer().lemmatize()   ~> Berfungsi untuk melakukan lemmatizer pada suatu kata.
- WordNetLemmatizer().lemmatize(<word>, "<pos>")
    - Nilai default untuk pos       → pos=”n” (noun)


